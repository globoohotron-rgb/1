#!/usr/bin/env python3
import argparse, csv, json, sys, re, base64, math, hashlib
from pathlib import Path
from datetime import datetime, timedelta

ROOT = Path(__file__).resolve().parent.parent

# ---------- IO helpers ----------
def _read_csv(p: Path):
    with p.open(newline='', encoding='utf-8') as f:
        return list(csv.DictReader(f))

def _write_csv(p: Path, header, rows):
    p.parent.mkdir(parents=True, exist_ok=True)
    with p.open('w', newline='', encoding='utf-8') as f:
        w = csv.writer(f); w.writerow(header); w.writerows(rows)

def _ensure_placeholder_targets(p: Path):
    _write_csv(p, ["symbol","weight"], [["AAA",0.5],["BBB",-0.5]])

def _ensure_placeholder_returns(p: Path):
    _write_csv(p, ["symbol","r"], [["AAA",0.01],["BBB",-0.005],["CCC",0.0],["DDD",0.0]])

# ---------- tolerant column picking ----------
_num = re.compile(r"^[\s+-]?\d+(\.\d+)?([eE][+-]?\d+)?\s*$")
def _numeric_score(rows, key):
    ok = 0
    for r in rows:
        v = r.get(key, "")
        if isinstance(v, (int, float)): ok += 1; continue
        if isinstance(v, str) and _num.match(v):
            try: float(v); ok += 1
            except: pass
    return ok
def _guess_ci(keys, candidates):
    kl = {k.lower(): k for k in keys}
    for c in candidates:
        k = kl.get(c.lower())
        if k: return k
    return None
def _pick_symbol_key(keys):
    return _guess_ci(keys, ("symbol","ticker","asset","secid","code","id","isin","ric","name")) or list(keys)[0]
def _pick_weight_key(rows):
    keys = rows[0].keys()
    k = _guess_ci(keys, ("w_final","weight","w","target_weight","w_pre","weight_total"))
    return k or max(keys, key=lambda key: _numeric_score(rows, key))
def _pick_return_key(rows):
    keys = rows[0].keys()
    k = _guess_ci(keys, ("r","ret","return","r1d","log_ret","r_d1","gross_return"))
    return k or max(keys, key=lambda key: _numeric_score(rows, key))

# ---------- perf core ----------
def _float_str(x: float) -> str: return format(float(x), ".15g")

def _perf_compute_and_write(date_str: str):
    d = datetime.strptime(date_str, '%Y-%m-%d').date()
    d1 = d + timedelta(days=1)
    targets_path = ROOT / "targets" / f"{d.isoformat()}.csv"
    returns_path = ROOT / "returns" / f"{d1.isoformat()}.csv"
    if not targets_path.exists():
        _ensure_placeholder_targets(targets_path); print(f"NOTE: created placeholder {targets_path}", file=sys.stderr)
    if not returns_path.exists():
        _ensure_placeholder_returns(returns_path); print(f"NOTE: created placeholder {returns_path}", file=sys.stderr)
    t_rows = _read_csv(targets_path); r_rows = _read_csv(returns_path)
    if not t_rows or not r_rows: raise RuntimeError("empty CSV(s)")
    t_sym = _pick_symbol_key(t_rows[0].keys()); w_col = _pick_weight_key(t_rows)
    r_sym = _pick_symbol_key(r_rows[0].keys()); r_col = _pick_return_key(r_rows)
    rmap = {}
    for row in r_rows:
        try: rmap[row[r_sym]] = float(row[r_col])
        except: pass
    gross = 0.0
    for row in t_rows:
        try:
            s = row[t_sym]; w = float(row[w_col]); r = rmap.get(s)
            if r is None: continue
            gross += w * r
        except: continue
    out = {'date': d.isoformat(), 'gross_return': gross}
    out_path = ROOT / "performance" / f"{d.isoformat()}.json"
    out_path.parent.mkdir(parents=True, exist_ok=True)
    with out_path.open('w', encoding='utf-8') as f:
        json.dump(out, f, ensure_ascii=False, separators=(',', ':'))
    return gross

# ---------- equity curve (CSV + PNG) ----------
def _update_equity_csv(date_str: str, r: float):
    p = ROOT / "performance" / "equity.csv"
    p.parent.mkdir(parents=True, exist_ok=True)
    rows = []
    if p.exists():
        with p.open(newline='', encoding='utf-8') as f:
            rows = list(csv.DictReader(f))
    prev_equity = 1.0
    if rows:
        last_date = rows[-1].get("date")
        try: last_eq = float(rows[-1].get("equity","1"))
        except: last_eq = 1.0
        if last_date == date_str:
            if len(rows) >= 2:
                try: prev_equity = float(rows[-2].get("equity","1"))
                except: prev_equity = 1.0
                rows = rows[:-1]
            else:
                prev_equity = 1.0; rows = []
        else:
            prev_equity = last_eq
    equity = prev_equity * (1.0 + float(r))
    with p.open('w', newline='', encoding='utf-8') as f:
        w = csv.writer(f); w.writerow(["date","r","equity"])
        for row in rows:
            w.writerow([row.get("date",""), row.get("r",""), row.get("equity","")])
        w.writerow([date_str, _float_str(r), _float_str(equity)])

def _write_placeholder_png(path: Path):
    b64 = "iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAQAAAC1HAwCAAAAC0lEQVR42mP8/x8AAwMB/6X5S8QAAAAASUVORK5CYII="
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_bytes(base64.b64decode(b64))

def _plot_equity_png():
    csv_path = ROOT / "performance" / "equity.csv"
    png_path = ROOT / "docs" / "equity.png"
    png_path.parent.mkdir(parents=True, exist_ok=True)
    try:
        import matplotlib; matplotlib.use("Agg")
        import matplotlib.pyplot as plt
        from datetime import datetime as _dt
        rows = _read_csv(csv_path)
        if not rows: raise RuntimeError("empty equity.csv")
        xs, ys = [], []
        for r in rows:
            if not r.get("date") or not r.get("equity"): continue
            xs.append(_dt.strptime(r["date"], "%Y-%m-%d"))
            ys.append(float(r["equity"]))
        plt.figure(figsize=(8,4))
        plt.plot(xs, ys)
        plt.title("Equity Curve"); plt.xlabel("Date"); plt.ylabel("Equity"); plt.grid(True, alpha=0.3)
        plt.tight_layout(); plt.savefig(png_path, dpi=150); plt.close()
    except Exception as e:
        print(f"NOTE: matplotlib unavailable or failed ({e}); writing placeholder PNG", file=sys.stderr)
        _write_placeholder_png(png_path)

# ---------- stats ----------
def _compute_stats():
    p = ROOT / "performance" / "equity.csv"
    if not p.exists(): raise FileNotFoundError("performance/equity.csv not found")
    rows = _read_csv(p)
    if not rows: raise RuntimeError("performance/equity.csv is empty")
    r_list, e_list = [], []
    for row in rows:
        try:
            r_list.append(float(row.get("r", "0")))
            e_list.append(float(row.get("equity", "1")))
        except: continue
    n = len(e_list)
    cum = (e_list[-1] - 1.0) if n else 0.0
    if len(r_list) >= 2:
        mu = sum(r_list) / len(r_list)
        var = sum((x - mu) ** 2 for x in r_list) / len(r_list)
        vol = math.sqrt(var)
    else:
        vol = 0.0
    mdd, peak = 0.0, 1.0
    for e in e_list:
        if e > peak: peak = e
        dd = (e / peak) - 1.0
        if dd < mdd: mdd = dd
    out = {"days": n, "cum": cum, "vol": vol, "mdd": mdd}
    out_path = ROOT / "performance" / "stats.json"
    out_path.parent.mkdir(parents=True, exist_ok=True)
    with out_path.open('w', encoding='utf-8') as f:
        json.dump(out, f, ensure_ascii=False, separators=(',', ':'))
    return n, cum, vol, mdd

# ---------- config + weights ----------
def _load_config():
    cfg_path = ROOT / "config" / "ats.yaml"
    cfg_path.parent.mkdir(parents=True, exist_ok=True)
    if not cfg_path.exists():
        cfg_path.write_text("softmax_tau: 0.5\nrisk_target_sigma: 0.10\n", encoding="utf-8")
        print(f"NOTE: created default config at {cfg_path}", file=sys.stderr)
    data = {"softmax_tau": 0.5, "risk_target_sigma": 0.10}
    for line in cfg_path.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        if not line or line.startswith("#") or ":" not in line: continue
        k, v = [x.strip() for x in line.split(":", 1)]
        try: data[k] = float(v)
        except: data[k] = v
    return data

def _score_for_symbol(sym: str) -> float:
    h = hashlib.md5(sym.encode("utf-8")).hexdigest()
    x = int(h[:8], 16) / 0xFFFFFFFF
    return 2.0 * x - 1.0

def _weights_from_scores(symbols, tau: float, sigma: float):
    tau = max(float(tau), 1e-9); sigma = float(sigma)
    raw = []
    for s in symbols:
        sc = _score_for_symbol(s)
        w = math.tanh(sc / tau)
        raw.append((s, w))
    denom = sum(abs(w) for _, w in raw) or 1.0
    scale = (sigma if sigma > 0 else 1.0) / denom
    return [(s, w * scale) for s, w in raw]

# ---------- commands ----------
def cmd_run(date_str: str) -> int:
    d = datetime.strptime(date_str, '%Y-%m-%d').date()
    cfg = _load_config()
    tau = float(cfg.get("softmax_tau", 0.5))
    sig = float(cfg.get("risk_target_sigma", 0.10))
    print(f"Using tau={tau}; σ_target={sig}")
    d1 = d + timedelta(days=1)
    ret_path = ROOT / "returns" / f"{d1.isoformat()}.csv"
    if ret_path.exists():
        r_rows = _read_csv(ret_path)
        sy_key = _pick_symbol_key(r_rows[0].keys()) if r_rows else "symbol"
        symbols = sorted({row.get(sy_key) for row in r_rows if row.get(sy_key)})
    else:
        symbols = ["AAA", "BBB", "CCC", "DDD"]
    t_path = ROOT / "targets" / f"{d.isoformat()}.csv"
    weights = _weights_from_scores(symbols, tau, sig)
    _write_csv(t_path, ["symbol","weight"], weights)
    _write_csv(ROOT / "orders" / f"{d.isoformat()}.csv",
               ["symbol","side","qty","px_ref","tc_est"], [["AAA",1,100,100.0,0.0001],["BBB",-1,100,50.0,0.0001]])
    _write_csv(ROOT / "execution" / f"{d.isoformat()}.csv",
               ["symbol","filled_qty","avg_px"], [["AAA",100,100.5],["BBB",100,49.8]])
    print(f" Run {d.isoformat()}: targets/orders/execution ready"); return 0

def cmd_perf(date_str: str) -> int:
    try: gross = _perf_compute_and_write(date_str)
    except Exception as e: print(f"ERR: {e}", file=sys.stderr); return 1
    print(f" Perf {date_str}: r={gross:.6f}"); return 0

def cmd_daily(date_str: str) -> int:
    if cmd_run(date_str) != 0: return 1
    try:
        gross = _perf_compute_and_write(date_str)
        _update_equity_csv(date_str, gross)
        _plot_equity_png()
    except Exception as e:
        print(f"ERR: {e}", file=sys.stderr); return 1
    print(f" Daily {date_str}: weights OK; r={gross:.6f}"); return 0

def cmd_stats() -> int:
    try:
        n, cum, vol, mdd = _compute_stats()
    except Exception as e:
        print(f"ERR: {e}", file=sys.stderr); return 1
    print(f"Stats: {n} days; Cum={cum:.6f}; Vol={vol:.6f}; MDD={mdd:.6f}")
    return 0

def cmd_summary() -> int:
    try:
        stats_path = ROOT / "performance" / "stats.json"
        if stats_path.exists():
            with stats_path.open(encoding='utf-8') as f:
                s = json.load(f)
        else:
            n, cum, vol, mdd = _compute_stats()
            s = {"days": n, "cum": cum, "vol": vol, "mdd": mdd}
        eq_path = ROOT / "performance" / "equity.csv"
        rows = _read_csv(eq_path)
        if not rows: raise RuntimeError("performance/equity.csv is empty")
        last = rows[-1]
        d = last.get("date", ""); r = float(last.get("r", "0")); e = float(last.get("equity", "1"))
    except Exception as e:
        print(f"ERR: {e}", file=sys.stderr); return 1
    print(f"Summary: {int(s.get('days',0))} days; Cum={float(s.get('cum',0.0)):.6f}; Vol={float(s.get('vol',0.0)):.6f}; MDD={float(s.get('mdd',0.0)):.6f}; last={d} r={r:.6f} equity={e:.6f}")
    return 0

def cmd_report(date_str: str) -> int:
    try:
        stats_path = ROOT / "performance" / "stats.json"
        if stats_path.exists():
            with stats_path.open(encoding='utf-8') as f:
                s = json.load(f)
        else:
            n, cum, vol, mdd = _compute_stats()
            s = {"days": n, "cum": cum, "vol": vol, "mdd": mdd}
        eq_path = ROOT / "performance" / "equity.csv"
        rows = _read_csv(eq_path)
        if not rows: raise RuntimeError("performance/equity.csv is empty")
        last = rows[-1]
        d_last = last.get("date", ""); r_last = float(last.get("r", "0")); e_last = float(last.get("equity", "1"))
        summary_line = f"Summary: {int(s.get('days',0))} days; Cum={float(s.get('cum',0.0)):.6f}; Vol={float(s.get('vol',0.0)):.6f}; MDD={float(s.get('mdd',0.0)):.6f}; last={d_last} r={r_last:.6f} equity={e_last:.6f}"
        out_path = ROOT / "docs" / f"report_{date_str}.md"
        out_path.parent.mkdir(parents=True, exist_ok=True)
        md = f"# Report {date_str}\n\n```\n{summary_line}\n```\n\n![Equity curve](docs/equity.png)\n"
        out_path.write_text(md, encoding='utf-8')
    except Exception as e:
        print(f"ERR: {e}", file=sys.stderr); return 1
    print(f" Report {date_str} written"); return 0

def cmd_backfill(date_from: str, date_to: str) -> int:
    try:
        d0 = datetime.strptime(date_from, '%Y-%m-%d').date()
        d1 = datetime.strptime(date_to, '%Y-%m-%d').date()
    except ValueError:
        print("ERR: --from/--to must be YYYY-MM-DD", file=sys.stderr); return 2
    if d0 > d1:
        print("ERR: --from must be <= --to", file=sys.stderr); return 2
    cur = d0; step = timedelta(days=1)
    while cur <= d1:
        rc = cmd_daily(cur.isoformat())
        if rc != 0: return rc
        cur += step
    return 0

def cmd_doctor() -> int:
    req = [ROOT / "performance" / "equity.csv",
           ROOT / "performance" / "stats.json",
           ROOT / "docs" / "equity.png"]
    missing = [str(p) for p in req if not p.exists()]
    if missing:
        print("HEALTH: FAIL  missing: " + ", ".join(missing)); return 1
    print("HEALTH: PASS"); return 0

def main():
    p = argparse.ArgumentParser(prog='ats'); sub = p.add_subparsers(dest='cmd', required=True)
    p_r = sub.add_parser('run', help='produce targets/orders/execution (MVP)'); p_r.add_argument('--date', required=True)
    p_p = sub.add_parser('perf', help='compute daily gross return'); p_p.add_argument('--date', required=True)
    p_d = sub.add_parser('daily', help='run + perf + equity update'); p_d.add_argument('--date', required=True)
    sub.add_parser('stats', help='print Cum/Vol/MDD and save to performance/stats.json')
    sub.add_parser('summary', help='print one-line summary from equity.csv + stats.json')
    p_rep = sub.add_parser('report', help='write docs/report_<date>.md with summary + chart'); p_rep.add_argument('--date', required=True)
    p_bf = sub.add_parser('backfill', help='run daily for each date in range (inclusive)')
    p_bf.add_argument('--from', dest='date_from', required=True); p_bf.add_argument('--to', dest='date_to', required=True)
    sub.add_parser('doctor', help='health check: required artifacts exist')

    a = p.parse_args()
    if a.cmd=='run': sys.exit(cmd_run(a.date))
    if a.cmd=='perf': sys.exit(cmd_perf(a.date))
    if a.cmd=='daily': sys.exit(cmd_daily(a.date))
    if a.cmd=='stats': sys.exit(cmd_stats())
    if a.cmd=='summary': sys.exit(cmd_summary())
    if a.cmd=='report': sys.exit(cmd_report(a.date))
    if a.cmd=='backfill': sys.exit(cmd_backfill(a.date_from, a.date_to))
    if a.cmd=='doctor': sys.exit(cmd_doctor())

if __name__ == '__main__': main()
